{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright **`(c)`** 2022 Giovanni Squillero `<squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Lab 2: ES\n",
    "\n",
    "## Task\n",
    "\n",
    "Write agents able to play [*Nim*](https://en.wikipedia.org/wiki/Nim), with an arbitrary number of rows and an upper bound $k$ on the number of objects that can be removed in a turn (a.k.a., *subtraction game*).\n",
    "\n",
    "The goal of the game is to **avoid** taking the last object.\n",
    "\n",
    "* Task2.1: An agent using fixed rules based on *nim-sum* (i.e., an *expert system*)\n",
    "* Task2.2: An agent using evolved rules using ES\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Create the directory `lab2` inside your personal course repository for the course \n",
    "* Put a `README.md` and your solution (all the files, code and auxiliary data if needed)\n",
    "\n",
    "## Notes\n",
    "\n",
    "* Working in group is not only allowed, but recommended (see: [Ubuntu](https://en.wikipedia.org/wiki/Ubuntu_philosophy) and [Cooperative Learning](https://files.eric.ed.gov/fulltext/EJ1096789.pdf)). Collaborations must be explicitly declared in the `README.md`.\n",
    "* [Yanking](https://www.emacswiki.org/emacs/KillingAndYanking) from the internet is allowed, but sources must be explicitly declared in the `README.md`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T08:38:33.663784Z",
     "start_time": "2023-11-18T08:38:33.638896Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from pprint import pprint, pformat\n",
    "from collections import namedtuple\n",
    "import random\n",
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *Nim* and *Nimply* classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T08:38:33.665254Z",
     "start_time": "2023-11-18T08:38:33.641562Z"
    }
   },
   "outputs": [],
   "source": [
    "Nimply = namedtuple(\"Nimply\", \"row, num_objects\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T08:38:33.665592Z",
     "start_time": "2023-11-18T08:38:33.644503Z"
    }
   },
   "outputs": [],
   "source": [
    "class Nim:\n",
    "    def __init__(self, num_rows: int, k: int = None) -> None:\n",
    "        self._rows = [i * 2 + 1 for i in range(num_rows)]\n",
    "        self._k = k if k is not None else self._rows[-1]\n",
    "\n",
    "    def __bool__(self):\n",
    "        return sum(self._rows) > 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<\" + \" \".join(str(_) for _ in self._rows) + \">\"\n",
    "\n",
    "    @property\n",
    "    def rows(self) -> tuple:\n",
    "        return tuple(self._rows)\n",
    "    \n",
    "    @property\n",
    "    def k(self):\n",
    "        return self._k\n",
    "\n",
    "    def nimming(self, ply: Nimply) -> None:\n",
    "        row, num_objects = ply\n",
    "        assert self._rows[row] >= num_objects\n",
    "        assert self._k is None or num_objects <= self._k\n",
    "        self._rows[row] -= num_objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample (and silly) startegies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T08:38:33.665851Z",
     "start_time": "2023-11-18T08:38:33.647278Z"
    }
   },
   "outputs": [],
   "source": [
    "def pure_random(state: Nim) -> Nimply:\n",
    "    \"\"\"A completely random move\"\"\"\n",
    "    row = random.choice([r for r, c in enumerate(state.rows) if c > 0])\n",
    "    num_objects = random.randint(1, min(state.rows[row], state.k))\n",
    "    return Nimply(row, num_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T08:38:33.665909Z",
     "start_time": "2023-11-18T08:38:33.649726Z"
    }
   },
   "outputs": [],
   "source": [
    "def gabriele(state: Nim) -> Nimply:\n",
    "    \"\"\"Pick always the maximum possible number of the lowest row\"\"\"\n",
    "    possible_moves = [(r, o) for r, c in enumerate(state.rows) for o in range(1, min(c + 1, state.k))]\n",
    "    return Nimply(*max(possible_moves, key=lambda m: (-m[0], m[1])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This strategies consists in select the rows with the max number of objects and take from it a number proportional to the ratio between the max number of remaining moves and the total number of moves"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def adaptive(state: Nim) -> Nimply:\n",
    "    \"\"\"A strategy that can adapt its parameters\"\"\"\n",
    "    remaining_moves = sum(state.rows) - 1;\n",
    "    tot_moves = sum([i * 2 + 1 for i in range(NIM_ROWS)])\n",
    "    genome = remaining_moves/tot_moves\n",
    "    \n",
    "    index_max_rows = state.rows.index(max(state.rows))\n",
    "    objects_to_take = max(min(int(genome * max(state.rows)), state.k), 1)\n",
    "    return Nimply(index_max_rows, objects_to_take)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T08:38:33.674952Z",
     "start_time": "2023-11-18T08:38:33.652037Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T08:38:33.693085Z",
     "start_time": "2023-11-18T08:38:33.655520Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def nim_sum(state: Nim) -> int:\n",
    "    tmp = np.array([tuple(int(x) for x in f\"{c:032b}\") for c in state.rows])\n",
    "    xor = tmp.sum(axis=0) % 2\n",
    "    return int(\"\".join(str(_) for _ in xor), base=2)\n",
    "\n",
    "\n",
    "def analize(raw: Nim) -> dict:\n",
    "    cooked = dict()\n",
    "    cooked[\"possible_moves\"] = dict()\n",
    "    for ply in (Nimply(r, o) for r, c in enumerate(raw.rows) for o in range(1, c+1 if raw.k is None else min(c+1, raw.k))):\n",
    "        tmp = deepcopy(raw)\n",
    "        tmp.nimming(ply)\n",
    "        cooked[\"possible_moves\"][ply] = nim_sum(tmp)\n",
    "    return cooked\n",
    "\n",
    "\n",
    "def optimal(state: Nim) -> Nimply:\n",
    "    analysis = analize(state)\n",
    "    logging.debug(f\"analysis:\\n{pformat(analysis)}\")\n",
    "    spicy_moves = [ply for ply, ns in analysis[\"possible_moves\"].items() if ns != 0 and ply.num_objects <= state.k]\n",
    "    if not spicy_moves:\n",
    "        spicy_moves = list(analysis[\"possible_moves\"].keys())\n",
    "    ply = random.choice(spicy_moves)\n",
    "    return ply"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This function enhanced the previous optimal strategy adding the case in which the game end up in a position with only one row of size 2 or more and at this point the nim sum is not equal to zero so the best move is to reduce this to a size of 0 or 1 and leaving an odd number of rows with size 1, from which all the moves are constrained"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def expert_agent(state: Nim) -> Nimply:\n",
    "    analysis = analize(state)\n",
    "    \n",
    "    #check if remains only one rows with size 2 or more and eventually remove 2 objects from the rows with 2 elements if the number of rows with one object is even, in the other case remove one \n",
    "    if state.rows.count(1) == (len(state.rows) - state.rows.count(0))-1:\n",
    "        row, objects = [(row, objects) for row, objects in enumerate(state.rows) if objects > 1][0]\n",
    "        objects_to_remove = objects\n",
    "        if (state.rows.count(1) % 2) != 1:\n",
    "            objects_to_remove = objects-1\n",
    "        return Nimply(row, objects_to_remove if state.k is None else min(objects_to_remove, state.k))  \n",
    "    spicy_moves = [ply for ply, ns in analysis[\"possible_moves\"].items() if ns != 0]\n",
    "    if not spicy_moves:\n",
    "        spicy_moves = list(analysis[\"possible_moves\"].keys())\n",
    "    ply = random.choice(spicy_moves)\n",
    "    return ply"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T08:38:33.694480Z",
     "start_time": "2023-11-18T08:38:33.658714Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "this function simulate a match between the evolutionary and the expert agent"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "\n",
    "def play_game_against_expert(nim: Nim, agent) -> int:\n",
    "    \n",
    "    logging.info(f\"init : {nim}\")\n",
    "    player = random.randint(0, 1)\n",
    "\n",
    "    while nim: \n",
    "        current_strategy = expert_agent if player == 0 else random.choices(agent[0], weights=agent[1], k=1)[0]\n",
    "        #print(\"CURRENT STRATEGIES IS: \" + current_strategy.__name__)\n",
    "        ply = current_strategy(nim)\n",
    "        logging.info(f\"ply: player {player} plays {ply}\")\n",
    "        nim.nimming(ply)\n",
    "        logging.info(f\"status: {nim}\")\n",
    "        player = 1 - player\n",
    "    logging.info(f\"status: Player {player} won!\")\n",
    "    return player\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T08:38:33.695005Z",
     "start_time": "2023-11-18T08:38:33.662546Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here the evolutionary strategy that consist in creating as population agent with 4 different strategies, each one with a different weight to compute the probabilities of being chosen during the game to compute the move\n",
    "The evolutionary parameters are:\n",
    "* Parent selection $\\mu$: 1/3\n",
    "* Reproduction $\\rho$ : 1\n",
    "* Mutation rate $\\gamma$: 0.2\n",
    "\n",
    "The other are:\n",
    "* POPULATION_SIZE: How many agents are part of every generation\n",
    "* STRATEGIES: The list of all the different strategies that can be used by an agent\n",
    "* AGENT_STRATEGIES: How many strategies an agent has\n",
    "\n",
    "The steps are:\n",
    "* The population is reduced in every generation by first selecting the remaining parents assigning a weight that depends on the fitness value and randomly choose which parent eliminate proportionally to the weight\n",
    "* Then based on the mutation rate probability, it is applied to every remaining parent to restore the population size:\n",
    "    * a mutation by changing randomly one strategy and one weight\n",
    "    * or a crossover by mix the strategies and the weights of 2 different parents\n",
    "\n",
    "Every 5 generation is printed the best and the average fitness to check how the evolution is going.\n",
    "Expectation are that the expert agent wins the most part of the games and that the agent tend to preserve and maximize the weight of the optimal strategy which is like the one used by the expert agent with except for the final part where it does not make the optimal move"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T09:27:23.926646Z",
     "start_time": "2023-11-18T08:38:33.670282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Generation: 0 - Best Fitness: 0.3 - Avg Fitness: 0.18793103448275864\n",
      "- Generation: 5 - Best Fitness: 0.4 - Avg Fitness: 0.1716666666666667\n",
      "- Generation: 10 - Best Fitness: 0.4 - Avg Fitness: 0.15666666666666665\n",
      "- Generation: 15 - Best Fitness: 0.35 - Avg Fitness: 0.1716666666666667\n",
      "- Generation: 20 - Best Fitness: 0.35 - Avg Fitness: 0.19166666666666668\n",
      "- Generation: 25 - Best Fitness: 0.35 - Avg Fitness: 0.18333333333333338\n",
      "- Generation: 30 - Best Fitness: 0.35 - Avg Fitness: 0.205\n",
      "- Generation: 35 - Best Fitness: 0.35 - Avg Fitness: 0.17833333333333334\n",
      "- Generation: 40 - Best Fitness: 0.45 - Avg Fitness: 0.2033333333333333\n",
      "- Generation: 45 - Best Fitness: 0.35 - Avg Fitness: 0.19333333333333333\n",
      "Agent 0 using functions: ['optimal', 'adaptive', 'optimal', 'adaptive', 'pure_random', 'optimal', 'gabriele', 'adaptive'], weights: [1, 3, 1, 4, 2, 2, 4, 2] with a fitness value of: 0.2\n",
      "Agent 1 using functions: ['gabriele', 'adaptive', 'optimal', 'adaptive', 'pure_random', 'optimal', 'adaptive', 'adaptive'], weights: [1, 3, 1, 4, 2, 1, 4, 4] with a fitness value of: 0.1\n",
      "Agent 2 using functions: ['adaptive', 'gabriele', 'adaptive', 'adaptive', 'pure_random', 'optimal', 'gabriele', 'adaptive'], weights: [4, 3, 1, 4, 2, 2, 4, 2] with a fitness value of: 0.15\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Evolutionary parameters\n",
    "POPULATION_SIZE = 30\n",
    "MUTATION_RATE = 0.2\n",
    "NUMBER_GENERATIONS = 50\n",
    "NIM_ROWS = 10\n",
    "STRATEGIES = [gabriele, pure_random, optimal, adaptive]\n",
    "AGENT_STRATEGIES = 8\n",
    "\n",
    "def generate_random_agent():\n",
    "    \n",
    "    agent_strategies =  [random.choices(STRATEGIES, weights=[random.randint(1, 4) for _ in range(len(STRATEGIES))])[0] for _ in range(AGENT_STRATEGIES)]\n",
    "    strategies_weights = random.choices([1, 2, 3, 4], k=AGENT_STRATEGIES)\n",
    "    return (agent_strategies, strategies_weights)\n",
    "\n",
    "\n",
    "def fitness(agent, number_of_matches=20):\n",
    "    victories_agent = 0\n",
    "    for i in range(number_of_matches):\n",
    "        number_of_rows = random.randint(2, 10)\n",
    "        max_k = random.randint(2, 10)\n",
    "        nim = Nim(NIM_ROWS, max_k)\n",
    "        results = play_game_against_expert(nim, agent)\n",
    "        victories_agent += 1 if results == 1 else 0\n",
    "        \n",
    "    return victories_agent/number_of_matches \n",
    "\n",
    "\n",
    "def mutate(agent):\n",
    "    strategies, weights = agent\n",
    "    mutated_strategies = strategies[:]  \n",
    "    idx_to_mutate = random.randint(0, len(mutated_strategies) - 1)\n",
    "    mutated_strategies[idx_to_mutate] = random.choice(STRATEGIES)\n",
    "    mutated_weights = weights[:]\n",
    "    mutated_weights[random.randint(0, len(mutated_strategies) -1 )] = random.choice([1, 2, 3, 4])\n",
    "    return mutated_strategies, mutated_weights\n",
    "\n",
    "\n",
    "def reproduce(agent1, agent2):\n",
    "    strategies1, weights1 = agent1\n",
    "    strategies2, weights2 = agent2\n",
    "    crossover_point = random.randint(0, len(strategies1))\n",
    "    child_strategies = strategies1[:crossover_point] + strategies2[crossover_point:]\n",
    "    child_weights = weights1[:crossover_point] + weights2[crossover_point:]\n",
    "    return child_strategies, child_weights  \n",
    "\n",
    "# Initialize the population\n",
    "population = [generate_random_agent() for _ in range(POPULATION_SIZE - 1)]\n",
    "\n",
    "# Evolutionary loop\n",
    "for generation in range(NUMBER_GENERATIONS):\n",
    "    # Evaluate current generation\n",
    "    fitness_scores = [fitness(agent) for agent in population]\n",
    "\n",
    "    if generation % 5 == 0:\n",
    "        max_fitness = max(fitness_scores)\n",
    "        print(f\"- Generation: {generation} - Best Fitness: {max_fitness} - Avg Fitness: {sum(fitness_scores) / len(fitness_scores)}\")\n",
    "\n",
    "    # Keep the best agent from the previous generation\n",
    "    best_of_generation = max(population, key=fitness)\n",
    "    \n",
    "    # Select parents\n",
    "    selected_parents = random.choices(population, weights=fitness_scores, k=POPULATION_SIZE // 3)\n",
    "\n",
    "    # Create next generation\n",
    "    new_population = [best_of_generation]  \n",
    "\n",
    "    for i in range(POPULATION_SIZE - 1):\n",
    "        if random.random() < MUTATION_RATE:\n",
    "            new_population.append(mutate(random.choice(selected_parents)))\n",
    "        else:\n",
    "            agent1 = random.choice(selected_parents)\n",
    "            agent2 = random.choice(selected_parents)\n",
    "            new_population.append(reproduce(agent1, agent2))\n",
    "\n",
    "    population = new_population\n",
    "\n",
    "# Print the best agents\n",
    "best_3_agents = sorted(population, key=fitness, reverse=True)[:3]\n",
    "for i, agent in enumerate(best_3_agents):\n",
    "    print(f\"Agent {i} using functions: {[func.__name__ for func in agent[0]]}, weights: {agent[1]} with a fitness value of: {fitness(agent)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the results the winning strategy is the adaptive one which is used more than the optimal \n",
    "To test it, here there are 4 simulations to test all the four strategies against the expert agent to confirm the result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pure_random strategy has a mean fitness value of 0.15000000000000005\n",
      "The gabriele strategy has a mean fitness value of 0.1305\n",
      "The optimal strategy has a mean fitness value of 0.19499999999999995\n",
      "The adaptive strategy has a mean fitness value of 0.2795000000000001\n"
     ]
    }
   ],
   "source": [
    "def test_strategies(agent):\n",
    "    sum_fitness = 0\n",
    "    for _ in range(100):\n",
    "        sum_fitness += fitness(agent)\n",
    "    print(f\"The {agent[0][0].__name__} strategy has a mean fitness value of {sum_fitness/100}\")\n",
    "    \n",
    "test_strategies(([pure_random], [1]))\n",
    "test_strategies(([gabriele], [1]))\n",
    "test_strategies(([optimal], [1]))\n",
    "test_strategies(([adaptive], [1]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-18T09:30:34.281030Z",
     "start_time": "2023-11-18T09:27:23.975139Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The tests confirm that the most successful strategy is adaptive, despite the fact that the expert agent wins much more than half the time"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('ci22-dPIXJ0_o-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "10197e8e2f2aa67e2c349105091c77f4cd384fce4877865f002d9ec653f96bc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
